{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941b2fa2",
   "metadata": {},
   "source": [
    "### Build a Simple LLM Application with LCEL\n",
    "In this quickstart we'll show you how to build a simple LLM application with LangChain. This application will translate text from English into another language. This is a relatively simple LLM application - it's just a single LLM call plus some prompting. Still, this is a great way to get started with LangChain - a lot of features can be built with just some prompting and an LLM call!\n",
    "\n",
    "After seeing this video, you'll have a high level overview of:\n",
    "\n",
    "- Using language models\n",
    "\n",
    "- Using PromptTemplates and OutputParsers\n",
    "\n",
    "- Using LangChain Expression Language (LCEL) to chain components together\n",
    "\n",
    "- Debugging and tracing your application using LangSmith\n",
    "\n",
    "- Deploying your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b82713d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you want to build a program that can answer questions using information from a bunch of documents, like a legal contract or a collection of research papers.  Doing this manually would be incredibly tedious.\n",
      "\n",
      "LangChain is a framework that makes this much easier.  It's like a toolbox full of pre-built components that let you:\n",
      "\n",
      "1. **Connect to your data:**  Load documents from various sources (PDFs, websites, databases, etc.).\n",
      "2. **Break it down:** Split long documents into smaller, manageable chunks.\n",
      "3. **Understand the meaning:** Use large language models (LLMs) like ChatGPT to understand the content of those chunks.\n",
      "4. **Answer questions:**  Use the LLM to answer your questions based on the understanding it gained from the documents.\n",
      "5. **Chain things together:**  Combine different components to build complex workflows, like summarizing documents, translating languages, or even creating chatbots with access to specific knowledge bases.\n",
      "\n",
      "Essentially, LangChain simplifies the process of building applications that use LLMs to interact with and reason over external data. It handles the messy parts, letting you focus on the application logic.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Use Gemini model (like Gemini Pro)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "response = model.generate_content(\"Explain LangChain in simple terms\")\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b50a2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from langchain_groq) (0.3.61)\n",
      "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
      "  Downloading groq-0.26.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (2.11.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.16.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain_groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain_groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\likith\\desktop\\gen_ai_vscode\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain_groq) (2.4.0)\n",
      "Downloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
      "Downloading groq-0.26.0-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: groq, langchain_groq\n",
      "\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 2/2 [langchain_groq]\n",
      "\n",
      "Successfully installed groq-0.26.0 langchain_groq-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74902da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E7E5E39280>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E7E82C88C0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2be531",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f049b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"Translate the following from English to French\"),\n",
    "    HumanMessage(content=\"Hello How are you?\")\n",
    "]\n",
    "\n",
    "result=model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16f94aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Bonjour, comment allez-vous ? \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 21, 'total_tokens': 32, 'completion_time': 0.02, 'prompt_time': 0.002221435, 'queue_time': 0.247718285, 'total_time': 0.022221435}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--06ee8307-179b-4f24-b7b5-57c814700d44-0', usage_metadata={'input_tokens': 21, 'output_tokens': 11, 'total_tokens': 32})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad7988b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour, comment allez-vous ? \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser=StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da996503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour ! Comment allez-vous ? \\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Using LCEL- chain the components\n",
    "chain=model|parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f8dee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prompt Templates\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "generic_template=\"Trnaslate the following into {language}:\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",generic_template),(\"user\",\"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2650ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=prompt.invoke({\"language\":\"French\",\"text\":\"Hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36724e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Chaining together components with LCEL\n",
    "chain=prompt|model|parser\n",
    "chain.invoke({\"language\":\"French\",\"text\":\"Hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cce06c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
