{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4429ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"yolov9_paper.pdf\")\n",
    "data = loader.load()  # entire PDF is loaded as a single Document\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a94128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents:  96\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# split data\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "\n",
    "print(\"Total number of documents: \",len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4784e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "291b8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "api_key=\"AIzaSyCdc0WBthBoU6EZewU35wfkOPW-8IyjYgk\"\n",
    "\n",
    "#Get an API key: \n",
    "# Head to https://ai.google.dev/gemini-api/docs/api-key to generate a Google AI API key. Paste in .env file\n",
    "\n",
    "# Embedding models: https://python.langchain.com/v0.1/docs/integrations/text_embedding/\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-1.5-flash\",  # Correct model name\n",
    "            temperature=0.3,\n",
    "            max_tokens=1024,\n",
    "            google_api_key=api_key\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8400df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set GOOGLE_API_KEY environment variable for langchain_google_genai client\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ea010eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=api_key # Explicitly pass API key here\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eea8bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(documents=docs, embedding=GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=api_key # Explicitly pass API key here\n",
    "))\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e91ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e052a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e855c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='PGI, or **Progressive Growth Investing**, is a strategy that focuses on steadily increasing investments over time, rather than making large lump-sum contributions.  There isn\\'t one single, universally defined \"PGI\" method, but the core principles remain consistent:\\n\\n**How PGI Works:**\\n\\n1. **Regular Contributions:**  The foundation of PGI is consistent, scheduled contributions. This could be weekly, bi-weekly, monthly, or quarterly, depending on individual circumstances and financial capabilities.\\n\\n2. **Gradual Increases:**  The key differentiator from simply regular investing is the *gradual increase* in contribution amounts.  This increase can be based on various factors, including:\\n\\n    * **Percentage Increases:**  A common approach is to increase contributions by a fixed percentage (e.g., 5% or 10%) annually or semi-annually.  This automatically adjusts to income growth and inflation.\\n    * **Fixed Dollar Increases:**  Another option is to increase contributions by a fixed dollar amount (e.g., $50 or $100) at set intervals. This is simpler to manage but may not scale as well with income growth.\\n    * **Income-Based Increases:**  Contributions are adjusted based on actual income increases.  This is more responsive to changes in financial circumstances but requires more manual adjustments.\\n\\n3. **Investment Vehicle:**  The contributions are typically invested in a diversified portfolio, such as mutual funds, ETFs, or individual stocks, depending on the investor\\'s risk tolerance and financial goals.\\n\\n4. **Long-Term Perspective:** PGI is a long-term strategy.  The power of compounding returns is maximized over many years.  Short-term market fluctuations are less impactful due to the consistent, incremental contributions.\\n\\n**Advantages of PGI:**\\n\\n* **Dollar-Cost Averaging:**  By investing regularly, you automatically buy more shares when prices are low and fewer when prices are high, mitigating the risk of investing a lump sum at a market peak.\\n* **Habit Formation:**  Regular contributions establish a disciplined saving and investing habit.\\n* **Flexibility:**  It\\'s easier to adjust contributions based on changing financial circumstances.\\n* **Accessibility:**  It\\'s accessible to individuals with varying income levels, as contributions can start small and gradually increase.\\n\\n\\n**Disadvantages of PGI:**\\n\\n* **Slower Growth (Initially):** Compared to a lump-sum investment, initial growth may be slower because contributions are smaller in the early stages.\\n* **Requires Discipline:**  Consistent contributions are crucial for the strategy to be effective.\\n\\n\\nIn summary, PGI is a practical and accessible investing strategy that leverages the power of consistent contributions and gradual increases to build wealth over the long term.  Its success depends on discipline and a long-term perspective.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--45075c32-8fc4-4b3f-bb12-babdf51bc16e-0' usage_metadata={'input_tokens': 17, 'output_tokens': 581, 'total_tokens': 598, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is new in YOLOv9?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed1acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
